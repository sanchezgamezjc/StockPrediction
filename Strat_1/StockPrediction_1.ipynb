{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5752236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "import pandas_ta as pta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2c26a",
   "metadata": {},
   "source": [
    "## Descarga datos y creaci√≥n dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab7bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_per = 400\n",
    "stock = 'EURGBP=X'\n",
    "\n",
    "end = dt.date.today()- dt.timedelta(days=2)\n",
    "start = end - dt.timedelta(days=(sample_per))\n",
    "interval = '1h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c3e1a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "database = yf.download(stock, start=start, end=end, interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3212064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMA (200,50,20)\n",
    "database['200ema'] = database['Adj Close'].ewm(span=200).mean()\n",
    "database['50ema'] = database['Adj Close'].ewm(span=50, adjust=False).mean()\n",
    "database['20ema'] = database['Adj Close'].ewm(span=20, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2d4f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>200ema</th>\n",
       "      <th>50ema</th>\n",
       "      <th>20ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-29 23:00:00+01:00</th>\n",
       "      <td>0.90660</td>\n",
       "      <td>0.90760</td>\n",
       "      <td>0.90656</td>\n",
       "      <td>0.90730</td>\n",
       "      <td>0.90730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907300</td>\n",
       "      <td>0.907300</td>\n",
       "      <td>0.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 00:00:00+01:00</th>\n",
       "      <td>0.90746</td>\n",
       "      <td>0.90781</td>\n",
       "      <td>0.90710</td>\n",
       "      <td>0.90751</td>\n",
       "      <td>0.90751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907406</td>\n",
       "      <td>0.907308</td>\n",
       "      <td>0.907320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 01:00:00+01:00</th>\n",
       "      <td>0.90751</td>\n",
       "      <td>0.90774</td>\n",
       "      <td>0.90664</td>\n",
       "      <td>0.90702</td>\n",
       "      <td>0.90702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907276</td>\n",
       "      <td>0.907297</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 02:00:00+01:00</th>\n",
       "      <td>0.90697</td>\n",
       "      <td>0.90717</td>\n",
       "      <td>0.90660</td>\n",
       "      <td>0.90683</td>\n",
       "      <td>0.90683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907163</td>\n",
       "      <td>0.907279</td>\n",
       "      <td>0.907247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 03:00:00+01:00</th>\n",
       "      <td>0.90688</td>\n",
       "      <td>0.90730</td>\n",
       "      <td>0.90650</td>\n",
       "      <td>0.90689</td>\n",
       "      <td>0.90689</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907107</td>\n",
       "      <td>0.907263</td>\n",
       "      <td>0.907213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Open     High      Low    Close  Adj Close  \\\n",
       "2020-07-29 23:00:00+01:00  0.90660  0.90760  0.90656  0.90730    0.90730   \n",
       "2020-07-30 00:00:00+01:00  0.90746  0.90781  0.90710  0.90751    0.90751   \n",
       "2020-07-30 01:00:00+01:00  0.90751  0.90774  0.90664  0.90702    0.90702   \n",
       "2020-07-30 02:00:00+01:00  0.90697  0.90717  0.90660  0.90683    0.90683   \n",
       "2020-07-30 03:00:00+01:00  0.90688  0.90730  0.90650  0.90689    0.90689   \n",
       "\n",
       "                           Volume    200ema     50ema     20ema  \n",
       "2020-07-29 23:00:00+01:00       0  0.907300  0.907300  0.907300  \n",
       "2020-07-30 00:00:00+01:00       0  0.907406  0.907308  0.907320  \n",
       "2020-07-30 01:00:00+01:00       0  0.907276  0.907297  0.907291  \n",
       "2020-07-30 02:00:00+01:00       0  0.907163  0.907279  0.907247  \n",
       "2020-07-30 03:00:00+01:00       0  0.907107  0.907263  0.907213  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963765d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close shi</th>\n",
       "      <th>200ema</th>\n",
       "      <th>50ema</th>\n",
       "      <th>20ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-29 23:00:00+01:00</th>\n",
       "      <td>0.90751</td>\n",
       "      <td>0.907300</td>\n",
       "      <td>0.907300</td>\n",
       "      <td>0.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 00:00:00+01:00</th>\n",
       "      <td>0.90702</td>\n",
       "      <td>0.907406</td>\n",
       "      <td>0.907308</td>\n",
       "      <td>0.907320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 01:00:00+01:00</th>\n",
       "      <td>0.90683</td>\n",
       "      <td>0.907276</td>\n",
       "      <td>0.907297</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 02:00:00+01:00</th>\n",
       "      <td>0.90689</td>\n",
       "      <td>0.907163</td>\n",
       "      <td>0.907279</td>\n",
       "      <td>0.907247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30 03:00:00+01:00</th>\n",
       "      <td>0.90689</td>\n",
       "      <td>0.907107</td>\n",
       "      <td>0.907263</td>\n",
       "      <td>0.907213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02 17:00:00+01:00</th>\n",
       "      <td>0.85828</td>\n",
       "      <td>0.857259</td>\n",
       "      <td>0.858798</td>\n",
       "      <td>0.858815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02 18:00:00+01:00</th>\n",
       "      <td>0.85797</td>\n",
       "      <td>0.857269</td>\n",
       "      <td>0.858778</td>\n",
       "      <td>0.858764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02 19:00:00+01:00</th>\n",
       "      <td>0.85812</td>\n",
       "      <td>0.857276</td>\n",
       "      <td>0.858746</td>\n",
       "      <td>0.858689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02 20:00:00+01:00</th>\n",
       "      <td>0.85811</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.858635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02 21:00:00+01:00</th>\n",
       "      <td>0.85816</td>\n",
       "      <td>0.857293</td>\n",
       "      <td>0.858698</td>\n",
       "      <td>0.858585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6780 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Adj Close shi    200ema     50ema     20ema\n",
       "2020-07-29 23:00:00+01:00        0.90751  0.907300  0.907300  0.907300\n",
       "2020-07-30 00:00:00+01:00        0.90702  0.907406  0.907308  0.907320\n",
       "2020-07-30 01:00:00+01:00        0.90683  0.907276  0.907297  0.907291\n",
       "2020-07-30 02:00:00+01:00        0.90689  0.907163  0.907279  0.907247\n",
       "2020-07-30 03:00:00+01:00        0.90689  0.907107  0.907263  0.907213\n",
       "...                                  ...       ...       ...       ...\n",
       "2021-09-02 17:00:00+01:00        0.85828  0.857259  0.858798  0.858815\n",
       "2021-09-02 18:00:00+01:00        0.85797  0.857269  0.858778  0.858764\n",
       "2021-09-02 19:00:00+01:00        0.85812  0.857276  0.858746  0.858689\n",
       "2021-09-02 20:00:00+01:00        0.85811  0.857285  0.858722  0.858635\n",
       "2021-09-02 21:00:00+01:00        0.85816  0.857293  0.858698  0.858585\n",
       "\n",
       "[6780 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = database.copy()\n",
    "\n",
    "data['Adj Close shi'] = data['Adj Close'].shift(-1)\n",
    "\n",
    "data = data[['Adj Close shi','200ema','50ema','20ema']]\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ec515",
   "metadata": {},
   "source": [
    "## Preparacion datos para el LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfeaca60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6780 entries, 2020-07-29 23:00:00+01:00 to 2021-09-02 21:00:00+01:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Adj Close shi  6780 non-null   float64\n",
      " 1   200ema         6780 non-null   float64\n",
      " 2   50ema          6780 non-null   float64\n",
      " 3   20ema          6780 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 264.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "711018d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5424, 1, 3) (5424,) (678, 1, 3) (678,) (678, 1, 3) (678,)\n"
     ]
    }
   ],
   "source": [
    "#Escalamos los valores con un MinMaxScaler\n",
    "values = data.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "values = scaled\n",
    "\n",
    "\n",
    "#Dividimos los datos entre train y test\n",
    "train, val = train_test_split(values, test_size=0.2, shuffle=False)\n",
    "\n",
    "#Dividimos datos validation entre validation y test\n",
    "val, test = train_test_split(val, test_size=0.5, shuffle=False)\n",
    "\n",
    "#Separamos los inputs de los outputs\n",
    "train_X, train_y = train[:, 1:], train[:,0]\n",
    "val_X, val_y = val[:, 1:], val[:,0]\n",
    "test_X, test_y = test[:, 1:], test[:, 0]\n",
    "\n",
    "\n",
    "#Generamos el reshape para poder incluir los valores en el modelo LSTM\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286d484",
   "metadata": {},
   "source": [
    "## Creamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62280955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos arquitectura del modelo\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64,  return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(256, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(512, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(1024, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e870af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 64)             17408     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 128)            98816     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 256)            394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 1024)           6295552   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 8,381,953\n",
      "Trainable params: 8,381,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c738d78b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:200 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 3) dtype=float32>, <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9512/218451454.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Entrenamos el modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:200 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 3) dtype=float32>, <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo\n",
    "history = model.fit(train_X, train_y, epochs=15, batch_size = 128, validation_data=[val_X, val_y], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fc645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos plot con los resultados\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e8e96",
   "metadata": {},
   "source": [
    "## Resultados con valores de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f09e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_re = yhat.reshape((yhat.shape[0], yhat.shape[1]))\n",
    "\n",
    "test_X_re = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "inv_yhat = np.concatenate((yhat_re, test_X_re), axis=1)\n",
    "\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_re = test_y.reshape((len(test_y), 1))\n",
    "\n",
    "inv_y = np.concatenate((test_y_re, test_X_re), axis=1)\n",
    "\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51237586",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'yhat':inv_yhat, 'y':inv_y})\n",
    "\n",
    "res['yhat_log'] = res['yhat'].pct_change()\n",
    "res['y_log'] = res['y'].pct_change()\n",
    "\n",
    "res['res'] = res['yhat_log']*res['y_log']\n",
    "\n",
    "lista =[]\n",
    "for index, row in res.iterrows():\n",
    "    if row['res'] > 0:\n",
    "        lista.append(1)\n",
    "    else:\n",
    "        lista.append(-1)\n",
    "\n",
    "serie = pd.Series(lista, index = res.index)\n",
    "\n",
    "res['Up_Down'] = serie\n",
    "\n",
    "res['Up_Down'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ac85f",
   "metadata": {},
   "source": [
    "## Resultados con todos los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_X, values_y = values[:, 1:], values[:,0]\n",
    "\n",
    "values_X = values_X.reshape((values_X.shape[0], 1, values_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aaa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(values_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_re = yhat.reshape((yhat.shape[0], yhat.shape[1]))\n",
    "\n",
    "values_X_re = values_X.reshape((values_X.shape[0], values_X.shape[2]))\n",
    "\n",
    "inv_yhat = np.concatenate((yhat_re, values_X_re), axis=1)\n",
    "\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac26c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_y_re = values_y.reshape((len(values_y), 1))\n",
    "\n",
    "inv_y = np.concatenate((values_y_re, values_X_re), axis=1)\n",
    "\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0259a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'yhat':inv_yhat, 'y':inv_y})\n",
    "\n",
    "res['yhat_log'] = res['yhat'].pct_change()\n",
    "res['y_log'] = res['y'].pct_change()\n",
    "\n",
    "res['res'] = res['yhat_log']*res['y_log']\n",
    "\n",
    "lista =[]\n",
    "for index, row in res.iterrows():\n",
    "    if row['res'] > 0:\n",
    "        lista.append(1)\n",
    "    else:\n",
    "        lista.append(-1)\n",
    "\n",
    "serie = pd.Series(lista, index = res.index)\n",
    "\n",
    "res['Up_Down'] = serie\n",
    "\n",
    "print(res['Up_Down'].value_counts())\n",
    "print()\n",
    "per = res['Up_Down'].value_counts()[1]/(res['Up_Down'].value_counts()[1]+res['Up_Down'].value_counts()[-1])\n",
    "print(f'% acierto: {per}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
